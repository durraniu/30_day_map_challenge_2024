[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "30 Day Map Challenge 2024",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nDay 6: Raster\n\n\n\n\n\n\nraster\n\n\nopenrouteservice\n\n\nfasterize\n\n\n\n\n\n\n\n\n\nNov 6, 2024\n\n\nUmair Durrani\n\n\n\n\n\n\n\n\n\n\n\n\nDay 5: A Journey\n\n\n\n\n\n\njourney\n\n\n\n\n\n\n\n\n\nNov 5, 2024\n\n\nUmair Durrani\n\n\n\n\n\n\n\n\n\n\n\n\nDay 4: Hexagons\n\n\n\n\n\n\nhexagons\n\n\ncollisions\n\n\n\n\n\n\n\n\n\nNov 4, 2024\n\n\nUmair Durrani\n\n\n\n\n\n\n\n\n\n\n\n\nDay 3: Polygons\n\n\n\n\n\n\npolygons\n\n\n\n\n\n\n\n\n\nNov 3, 2024\n\n\nUmair Durrani\n\n\n\n\n\n\n\n\n\n\n\n\nDay 2: Lines\n\n\n\n\n\n\nlines\n\n\n\n\n\n\n\n\n\nNov 2, 2024\n\n\nUmair Durrani\n\n\n\n\n\n\n\n\n\n\n\n\nDay 1: Points\n\n\n\n\n\n\npoints\n\n\ncrashapi\n\n\ntigris\n\n\n\n\n\n\n\n\n\nNov 1, 2024\n\n\nUmair Durrani\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/day1/day1.html",
    "href": "posts/day1/day1.html",
    "title": "Day 1: Points",
    "section": "",
    "text": "I used the crashapi package to gather fatal vehicle crashes for New York city for 2019-2020. Before looking at the maps, recall that stay-at-home orders were given in 2020 due to COVID-19. Therefore, the number of fatal crashes were expected to decrease in 2020 compared to 2019.\n\n# devtools::install_github(\"elipousson/crashapi\")\nlibrary(crashapi)\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(tigris)\nlibrary(patchwork)\n\nThere are 5 counties in New York City, so I made a function to download county data using the crashapi package:\n\nget_ny_county_data &lt;- function(county){\n  crashapi::get_fars(\n    year = c(2019, 2020),\n    state = \"New York\",\n    county = county,\n    details = FALSE,\n    geometry = TRUE\n  )\n}\n\nny_counties &lt;-  c(\"New York County\", \"Kings County\", \n    \"Queens County\", \"Bronx County\",\n    \"Richmond County\")\n\nny_crashes &lt;- purrr::map(\n  ny_counties,\n  ~ get_ny_county_data(.x)\n) \n\nny_crashes &lt;- purrr::set_names(ny_crashes, ny_counties) \n\nThen I created two lists of dataframes for each year:\n\nny_crashes19 &lt;- purrr::map(ny_crashes, ~ .x |&gt;\n                             janitor::clean_names() |&gt; \n                             dplyr::filter(case_year == \"2019\"))\nny_crashes20 &lt;- purrr::map(ny_crashes, ~ .x |&gt; \n                             janitor::clean_names() |&gt; \n                             dplyr::filter(case_year == \"2020\"))\n\n\n\nCity boundary was downloaded using the tigris package:\n\nny_places &lt;- places(state = \"NY\", cb = TRUE, progress_bar = FALSE)\nnyc_boundary &lt;- ny_places[ny_places$NAME == \"New York\", ]"
  },
  {
    "objectID": "posts/day1/day1.html#data",
    "href": "posts/day1/day1.html#data",
    "title": "Day 1: Points",
    "section": "",
    "text": "I used the crashapi package to gather fatal vehicle crashes for New York city for 2019-2020. Before looking at the maps, recall that stay-at-home orders were given in 2020 due to COVID-19. Therefore, the number of fatal crashes were expected to decrease in 2020 compared to 2019.\n\n# devtools::install_github(\"elipousson/crashapi\")\nlibrary(crashapi)\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(tigris)\nlibrary(patchwork)\n\nThere are 5 counties in New York City, so I made a function to download county data using the crashapi package:\n\nget_ny_county_data &lt;- function(county){\n  crashapi::get_fars(\n    year = c(2019, 2020),\n    state = \"New York\",\n    county = county,\n    details = FALSE,\n    geometry = TRUE\n  )\n}\n\nny_counties &lt;-  c(\"New York County\", \"Kings County\", \n    \"Queens County\", \"Bronx County\",\n    \"Richmond County\")\n\nny_crashes &lt;- purrr::map(\n  ny_counties,\n  ~ get_ny_county_data(.x)\n) \n\nny_crashes &lt;- purrr::set_names(ny_crashes, ny_counties) \n\nThen I created two lists of dataframes for each year:\n\nny_crashes19 &lt;- purrr::map(ny_crashes, ~ .x |&gt;\n                             janitor::clean_names() |&gt; \n                             dplyr::filter(case_year == \"2019\"))\nny_crashes20 &lt;- purrr::map(ny_crashes, ~ .x |&gt; \n                             janitor::clean_names() |&gt; \n                             dplyr::filter(case_year == \"2020\"))\n\n\n\nCity boundary was downloaded using the tigris package:\n\nny_places &lt;- places(state = \"NY\", cb = TRUE, progress_bar = FALSE)\nnyc_boundary &lt;- ny_places[ny_places$NAME == \"New York\", ]"
  },
  {
    "objectID": "posts/day1/day1.html#point-maps",
    "href": "posts/day1/day1.html#point-maps",
    "title": "Day 1: Points",
    "section": "Point Maps",
    "text": "Point Maps\nFinally, I was ready to visualize the single-vehicle fatal crashes in different counties. The function below does exactly that for a given year and county:\n\nplot_county_crashes &lt;- function(crash_list, num, total_vehs = \"1\"){\n  dataset &lt;- crash_list[[num]]\n  county &lt;- names(crash_list[num])\n  num_cases &lt;- nrow(dataset)\n  year &lt;- unique(dataset$case_year)\n  \n  ggplot() +\n  geom_sf(data = nyc_boundary, fill = NA, color = \"grey50\") +\n  geom_sf(\n    data = dataset |&gt; \n      dplyr::filter(totalvehicles == total_vehs),\n    aes(color =  totalvehicles),\n    alpha = 0.5\n  ) +\n  labs(title = paste0(county, \" (\", year, \")\"),\n       subtitle = paste0(\" (# of crashes: \", num_cases, \")\")) +\n  theme_void() +\n  theme(legend.position = \"none\")\n}\n\nAnd the following function plots the same county for both years:\n\ncreate_combined_plot &lt;- function(num,\n                                 list1 = ny_crashes19,\n                                 list2 = ny_crashes20\n                                 ){\n  plot_county_crashes(list1, num) | plot_county_crashes(list2, num)\n}\n\n\nMaps\n\ncreate_combined_plot(1)\n\n\n\n\n\n\n\ncreate_combined_plot(2)\n\n\n\n\n\n\n\ncreate_combined_plot(4)\n\n\n\n\n\n\n\ncreate_combined_plot(5)\n\n\n\n\n\n\n\n\nBronx county had twice the crashes in 2020 compared to 2019!\nAnd something is wrong with the data for Queens county:\n\ncreate_combined_plot(3)"
  },
  {
    "objectID": "posts/day2/day2.html",
    "href": "posts/day2/day2.html",
    "title": "Day 2: Lines",
    "section": "",
    "text": "I downloaded road network data from five cities using the osmdata package in R."
  },
  {
    "objectID": "posts/day2/day2.html#data",
    "href": "posts/day2/day2.html#data",
    "title": "Day 2: Lines",
    "section": "",
    "text": "I downloaded road network data from five cities using the osmdata package in R."
  },
  {
    "objectID": "posts/day2/day2.html#map",
    "href": "posts/day2/day2.html#map",
    "title": "Day 2: Lines",
    "section": "Map",
    "text": "Map\nI created an app with the help from shiny assistant. The app shows a road network and you need to guess the what city the road network is from. See if you can guess the city by looking at the road network:\n\n\n\nApp source\nYou can see the app source code here: https://github.com/durraniu/day_2_network_game"
  },
  {
    "objectID": "posts/day3/day3.html",
    "href": "posts/day3/day3.html",
    "title": "Day 3: Polygons",
    "section": "",
    "text": "I used the Urban Areas dataset from Bureau of Transportation Statistics website in the geojson format and loaded it in R via the sf package:\n\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(stringr)\nlibrary(patchwork)\n\nurban_areas &lt;- sf::st_read(here::here(\"posts/day3/data/NTAD_Urban_Areas_-6100623683100682750.geojson\"))\n\nReading layer `NTAD_Urban_Areas_-6100623683100682750' from data source \n  `D:\\30_day_map_challenge_2024\\posts\\day3\\data\\NTAD_Urban_Areas_-6100623683100682750.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 2645 features and 13 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -170.7893 ymin: -14.36541 xmax: 145.7916 ymax: 64.92889\nGeodetic CRS:  WGS 84\n\n\nAccording to the website:\n\nThere are 2,645 Urban Areas (UAs) in this data release with either a minimum population of 5,000 or a housing unit count of 2,000 units.\n\nInstead of plotting all the areas, I selected the top highly populated cities:\n\ntop_ua_names &lt;- c(\n  \"New York\",\n  \"Los Angeles\",\n  \"Chicago\",\n  \"Houston\",\n  \"Phoenix\",\n  \"Philadelphia\",\n  \"San Antonio\",\n  \"San Diego\"\n) \n\ntop_ua &lt;- urban_areas |&gt; \n  dplyr::filter(stringr::str_detect(NAME20, paste(top_ua_names, collapse = \"|\")))\n\nNext, I created a function to plot each urban area polygon. Unfortunately, ggplot2::facet_wrap does not work on sf data. So, I needed to plot each urban area separately:\n\ncreate_urban_polygons &lt;- function(row_num){\n  df_ua &lt;- top_ua[row_num, ]\n  city_name &lt;- df_ua$NAME20\n  land_area &lt;- format(df_ua$ALAND20/(1e+6), digits = 6, scientific = FALSE)\n  water_area &lt;- format(df_ua$AWATER20/(1e+6), digits = 4, scientific = FALSE)\n  \n  ggplot(\n    data = df_ua\n  ) +\n    geom_sf(fill = \"aquamarine\") +\n    labs(\n      title = city_name,\n      subtitle = paste0(\n        \"Land Area: \", land_area, \" sq. km\", \n        \"\\nWater Area: \", water_area, \" sq. km\"\n      )\n    )\n}\n\nlist_of_polygon_plots &lt;- lapply(\n  1:nrow(top_ua),\n  \\(x) create_urban_polygons(x)\n)\n\nNow, with patchwork, I was able to combine all the plots:\n\nggplot2::theme_set(theme_void(base_size = 20))\nall_urban_area_polygons &lt;- wrap_plots(list_of_polygon_plots, ncol = 2)\nggplot2::ggsave(filename = here::here(\"posts/day3/all_plots.png\"), \n                plot = all_urban_area_polygons, \n                width = 30,\n                height = 48, \n                units = \"in\", \n                dpi = 300, \n                bg = \"white\")\n\nAnd here are the polygons:"
  },
  {
    "objectID": "posts/day3/day3.html#data",
    "href": "posts/day3/day3.html#data",
    "title": "Day 3: Polygons",
    "section": "",
    "text": "I used the Urban Areas dataset from Bureau of Transportation Statistics website in the geojson format and loaded it in R via the sf package:\n\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(stringr)\nlibrary(patchwork)\n\nurban_areas &lt;- sf::st_read(here::here(\"posts/day3/data/NTAD_Urban_Areas_-6100623683100682750.geojson\"))\n\nReading layer `NTAD_Urban_Areas_-6100623683100682750' from data source \n  `D:\\30_day_map_challenge_2024\\posts\\day3\\data\\NTAD_Urban_Areas_-6100623683100682750.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 2645 features and 13 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -170.7893 ymin: -14.36541 xmax: 145.7916 ymax: 64.92889\nGeodetic CRS:  WGS 84\n\n\nAccording to the website:\n\nThere are 2,645 Urban Areas (UAs) in this data release with either a minimum population of 5,000 or a housing unit count of 2,000 units.\n\nInstead of plotting all the areas, I selected the top highly populated cities:\n\ntop_ua_names &lt;- c(\n  \"New York\",\n  \"Los Angeles\",\n  \"Chicago\",\n  \"Houston\",\n  \"Phoenix\",\n  \"Philadelphia\",\n  \"San Antonio\",\n  \"San Diego\"\n) \n\ntop_ua &lt;- urban_areas |&gt; \n  dplyr::filter(stringr::str_detect(NAME20, paste(top_ua_names, collapse = \"|\")))\n\nNext, I created a function to plot each urban area polygon. Unfortunately, ggplot2::facet_wrap does not work on sf data. So, I needed to plot each urban area separately:\n\ncreate_urban_polygons &lt;- function(row_num){\n  df_ua &lt;- top_ua[row_num, ]\n  city_name &lt;- df_ua$NAME20\n  land_area &lt;- format(df_ua$ALAND20/(1e+6), digits = 6, scientific = FALSE)\n  water_area &lt;- format(df_ua$AWATER20/(1e+6), digits = 4, scientific = FALSE)\n  \n  ggplot(\n    data = df_ua\n  ) +\n    geom_sf(fill = \"aquamarine\") +\n    labs(\n      title = city_name,\n      subtitle = paste0(\n        \"Land Area: \", land_area, \" sq. km\", \n        \"\\nWater Area: \", water_area, \" sq. km\"\n      )\n    )\n}\n\nlist_of_polygon_plots &lt;- lapply(\n  1:nrow(top_ua),\n  \\(x) create_urban_polygons(x)\n)\n\nNow, with patchwork, I was able to combine all the plots:\n\nggplot2::theme_set(theme_void(base_size = 20))\nall_urban_area_polygons &lt;- wrap_plots(list_of_polygon_plots, ncol = 2)\nggplot2::ggsave(filename = here::here(\"posts/day3/all_plots.png\"), \n                plot = all_urban_area_polygons, \n                width = 30,\n                height = 48, \n                units = \"in\", \n                dpi = 300, \n                bg = \"white\")\n\nAnd here are the polygons:"
  },
  {
    "objectID": "posts/day4/day4.html",
    "href": "posts/day4/day4.html",
    "title": "Day 4: Hexagons",
    "section": "",
    "text": "I re-used the New York City fatal collisions data from Day 1.\n\nlibrary(sf)\nlibrary(dplyr)\nlibrary(tmap)\n\nload(file = here::here(\"posts/day1/nyc_data.rda\"))\n\nThis loads the list of collisions for New York City for the years 2019 and 2020."
  },
  {
    "objectID": "posts/day4/day4.html#data",
    "href": "posts/day4/day4.html#data",
    "title": "Day 4: Hexagons",
    "section": "",
    "text": "I re-used the New York City fatal collisions data from Day 1.\n\nlibrary(sf)\nlibrary(dplyr)\nlibrary(tmap)\n\nload(file = here::here(\"posts/day1/nyc_data.rda\"))\n\nThis loads the list of collisions for New York City for the years 2019 and 2020."
  },
  {
    "objectID": "posts/day4/day4.html#create-hexagonal-grid-of-collisions",
    "href": "posts/day4/day4.html#create-hexagonal-grid-of-collisions",
    "title": "Day 4: Hexagons",
    "section": "Create hexagonal grid of collisions",
    "text": "Create hexagonal grid of collisions\nI create a function to create hexagonal grids. This is based on this awesome blog post.\n\ncreate_honeycomb &lt;- function(collision_list){\n  nyc &lt;- collision_list |&gt; dplyr::bind_rows()\n  \n  area_honeycomb_grid &lt;- st_make_grid(nyc, what = \"polygons\", square = FALSE)\n  honeycomb_grid_sf &lt;- st_sf(area_honeycomb_grid) |&gt; \n    dplyr::mutate(grid_id = 1:length(lengths(area_honeycomb_grid)))\n  \n  honeycomb_grid_sf$n_colli &lt;- lengths(st_intersects(honeycomb_grid_sf, nyc))\n  \n  # remove grid of 0 collisions\n  dplyr::filter(honeycomb_grid_sf, n_colli &gt; 0)\n}\n\nCreate grids for 2019:\n\nnyc_honeycomb19 &lt;- create_honeycomb(ny_crashes19)"
  },
  {
    "objectID": "posts/day4/day4.html#map",
    "href": "posts/day4/day4.html#map",
    "title": "Day 4: Hexagons",
    "section": "Map",
    "text": "Map\nReady to plot the grids:\n\ntmap_mode(\"view\")\n\ntm_shape(nyc_honeycomb19) +\n  tm_fill(\n    col = \"n_colli\",\n    palette = \"Reds\",\n    style = \"cont\",\n    title = \"Number of fatal collisions\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.vars = c(\n      \"Number of collisions: \" = \"n_colli\"\n    ),\n    popup.format = list(\n      n_colli = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)"
  },
  {
    "objectID": "posts/day5/day5.html",
    "href": "posts/day5/day5.html",
    "title": "Day 5: A Journey",
    "section": "",
    "text": "Around the World in Eighty Days\n\n\n\n\nFogg accepts a £20,000 wager to travel around the world in 80 days. ‘The unforeseen does not exist.’\n\n\n\n\n\n\n\n\n\nDetective Fix begins to pursue Fogg, suspecting him of bank robbery.\n\n\n\n\n\nFogg and Passepartout encounter a disrupted railway line and arrange for an elephant to continue their journey. \n\n\n\n\nFogg rescues Aouda, a widow who is to be sacrificed, saying, ‘I have yet twelve hours to save her!’ \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is a proof of concept to make a quarto closeread document with videos and images.\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{durrani2024,\n  author = {Durrani, Umair},\n  title = {Day 5: {A} {Journey}},\n  date = {2024-11-05},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nDurrani, Umair. 2024. “Day 5: A Journey.” November 5, 2024."
  },
  {
    "objectID": "posts/day5/test.html",
    "href": "posts/day5/test.html",
    "title": "Around the World in Eighty Days",
    "section": "",
    "text": "Around the World in Eighty Days\n\n\n\n\nFogg accepts a £20,000 wager to travel around the world in 80 days. ‘The unforeseen does not exist.’\n\n\n\n\n\n\n\n\n\nDetective Fix begins to pursue Fogg, suspecting him of bank robbery.\n\n\n\n\n\nFogg and Passepartout encounter a disrupted railway line and arrange for an elephant to continue their journey. \n\n\n\n\nFogg rescues Aouda, a widow who is to be sacrificed, saying, ‘I have yet twelve hours to save her!’ \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is an excerpt of the first three lines of A Poem (and a Painting) About the Suffering That Hides in Plain Sight by Elisa Gabbert, appearing in The New York Times on March 6, 2022.\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{durrani,\n  author = {Durrani, Umair},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nDurrani, Umair. n.d."
  },
  {
    "objectID": "posts/day6/day6.html",
    "href": "posts/day6/day6.html",
    "title": "Day 6: Raster",
    "section": "",
    "text": "This post is based on works from Milos Agathon (isochrone maps) and a lab from Spatial Methods in Community Research by Professor Noli Brazil.\nIn this post, I create cycling time isochrone rasters. The first step is to load the required libraries:\nlibrary(tidyverse)\nlibrary(openrouteservice)\nlibrary(mapview)\nlibrary(sf)\nlibrary(fasterize)\nlibrary(leaflet)\nThe Open Route Service provides isochrones for different transportation modes:\nopenrouteservice::ors_profile()\n\n               car                hgv               bike           roadbike \n     \"driving-car\"      \"driving-hgv\"  \"cycling-regular\"     \"cycling-road\" \n               mtb             e-bike            walking             hiking \n\"cycling-mountain\" \"cycling-electric\"     \"foot-walking\"      \"foot-hiking\" \n        wheelchair \n      \"wheelchair\"\nI’ll create the isochrones for two cities: Toronto, Ontario in Canada and Lahore, Punjab in Pakistan:\n## coordinates\ntor_lat &lt;- 43.75778976617083\ntor_lon &lt;- -79.39326677619596\n\nlhr_lat &lt;- 31.502425248570344\nlhr_lon &lt;- 74.30409916687087\n\ntor_coords &lt;- data.frame(tor_lon, tor_lat)\nlhr_coords &lt;- data.frame(lhr_lon, lhr_lat)"
  },
  {
    "objectID": "posts/day6/day6.html#query",
    "href": "posts/day6/day6.html#query",
    "title": "Day 6: Raster",
    "section": "Query",
    "text": "Query\nNext, I send queries to open route service to get isochrones:\n\ncycling_ams_tor &lt;- openrouteservice::ors_isochrones(\n  locations = tor_coords,\n  profile = \"cycling-regular\",\n  range = 3600,\n  interval = 600,\n  api_key = Sys.getenv(\"ORS_API_KEY\"),\n  output = \"sf\"\n)\n\ncycling_ams_lhr &lt;- openrouteservice::ors_isochrones(\n  locations = lhr_coords,\n  profile = \"cycling-regular\",\n  range = 3600,\n  interval = 600,\n  api_key = Sys.getenv(\"ORS_API_KEY\"),\n  output = \"sf\"\n)\n\n\ncycling_ams_tor\n\n\n  \n\n\n\nThen group by mins to create non-overlapping areas:\n\nsf::sf_use_s2(FALSE)\n\ncreate_cycling_ams_cropped &lt;- function(cycling_ams){\n  cycling_ams$mins &lt;- cycling_ams$value / 60\n  \n  cycling_ams |&gt;\n    dplyr::group_by(mins) |&gt;\n    sf::st_intersection() |&gt;\n    dplyr::ungroup()\n}\n\ncycling_ams_cropped_tor &lt;- create_cycling_ams_cropped(cycling_ams_tor)\ncycling_ams_cropped_lhr &lt;- create_cycling_ams_cropped(cycling_ams_lhr)\n\nAt this point, the sf objects above are not projected so they do no have any units:\n\nsf::st_crs(cycling_ams_cropped_tor)$units\n\nNULL\n\n\nBut we need units to rasterize them. So, I project them to the relevant projection for each city:\n\ncycling_ams_cropped_tor_proj &lt;- sf::st_transform(cycling_ams_cropped_tor, crs = 3161)\ncycling_ams_cropped_lhr_proj &lt;- sf::st_transform(cycling_ams_cropped_lhr, crs = 32643)\n\nsf::st_crs(cycling_ams_cropped_lhr_proj)$units\n\n[1] \"m\""
  },
  {
    "objectID": "posts/day6/day6.html#rasterize",
    "href": "posts/day6/day6.html#rasterize",
    "title": "Day 6: Raster",
    "section": "Rasterize",
    "text": "Rasterize\nGenerate a 100m resolution raster:\n\ntemplate_tor &lt;- raster(cycling_ams_cropped_tor_proj, resolution = 100)\ntemplate_lhr &lt;- raster(cycling_ams_cropped_lhr_proj, resolution = 100)\n\nAccording to the lab cited above: “Then use the fasterize() function to allocate the minimum overlapping value from our isochrones to each grid cell”:\n\niso_surface_tor &lt;- fasterize(cycling_ams_cropped_tor_proj, template_tor, \n                             field = \"mins\", fun = \"min\")\niso_surface_lhr &lt;- fasterize(cycling_ams_cropped_lhr_proj, template_lhr, \n                             field = \"mins\", fun = \"min\")"
  },
  {
    "objectID": "posts/day6/day6.html#map",
    "href": "posts/day6/day6.html#map",
    "title": "Day 6: Raster",
    "section": "Map",
    "text": "Map\n\npal_tor &lt;- colorNumeric(\"viridis\", cycling_ams_cropped_tor_proj$mins, na.color = \"transparent\")\npal_lhr &lt;- colorNumeric(\"viridis\", cycling_ams_cropped_lhr_proj$mins, na.color = \"transparent\")\n\nleaflet::leaflet() |&gt;\n  leaflet::addProviderTiles(\n    \"CartoDB.Positron\"\n  ) |&gt;\n  addRasterImage(iso_surface_tor, colors = pal_tor, opacity = 0.5) |&gt; \n  addLegend(\n    values = sort(as.numeric(as.character(cycling_ams_cropped_tor$mins))), \n    pal = pal_tor,\n    title = \"Cycling time in Toronto\"\n  )\n\n\n\n\nleaflet::leaflet() |&gt;\n  leaflet::addProviderTiles(\n    \"CartoDB.Positron\"\n  ) |&gt;\n  addRasterImage(iso_surface_lhr, colors = pal_lhr, opacity = 0.5) |&gt; \n  addLegend(\n    values = cycling_ams_cropped_lhr$mins, \n    pal = pal_lhr,\n    title = \"Cycling time in Lahore\"\n  )"
  }
]